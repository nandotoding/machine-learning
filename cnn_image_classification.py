# -*- coding: utf-8 -*-
"""CNN Image Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hBFfveoVYkR_Va40itwasZmIDAB90nMp

# Rock-Paper-Scissors Image Classification using Convolutional Neural Network

Importing all required libraries.
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import zipfile, os, datetime
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

"""Dataset preparation."""

!wget --no-check-certificate https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip -O /tmp/rockpaperscissors.zip

local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

os.listdir('/tmp')

os.listdir('/tmp/rockpaperscissors')

os.listdir('/tmp/rockpaperscissors/rps-cv-images')

rock_data_size = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/rock'))
scissors_data_size = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/scissors'))
paper_data_size = len(os.listdir('/tmp/rockpaperscissors/rps-cv-images/paper'))
data_size = rock_data_size + scissors_data_size + paper_data_size
print(rock_data_size)
print(scissors_data_size)
print(paper_data_size)
print(data_size)

base_dir = '/tmp/rockpaperscissors/rps-cv-images'
sample_path = base_dir + '/rock/' + os.listdir(base_dir + '/rock')[0]
sample_image = mpimg.imread(sample_path)
plt.figure()
plt.imshow(sample_image)
plt.grid(False)
plt.show()
sample_image.shape

"""Data preprocessing using `ImageDataGenerator()` method."""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    height_shift_range=0.25,
    width_shift_range=0.1,
    zoom_range=0.3,
    horizontal_flip=True,
    vertical_flip=True,
    brightness_range=[0.3, 0.9],
    shear_range=0.2,
    fill_mode='reflect',
    validation_split=0.4
)

train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(200, 300),
    color_mode='rgb',
    batch_size=32,
    class_mode='categorical',
    subset='training',
    seed=0
)

val_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(200, 300),
    color_mode='rgb',
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

"""Constructing the neural network model using  both convolutional and MLP layers."""

model = tf.keras.models.Sequential([
                                    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), input_shape=(200,300,3), activation='relu'),
                                    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
                                    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),
                                    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
                                    tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),
                                    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
                                    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'),
                                    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),
                                    tf.keras.layers.Flatten(),
                                    tf.keras.layers.Dense(256, activation='relu'),
                                    tf.keras.layers.Dropout(0.25),
                                    tf.keras.layers.Dense(512, activation='relu'),
                                    tf.keras.layers.Dropout(0.25),
                                    tf.keras.layers.Dense(512, activation='relu'),
                                    tf.keras.layers.Dropout(0.25),
                                    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

"""Compiling the model with a loss function, an optimizer, and a metrics.
(For the model is a classification problem with 2D one-hot-encoded output,
I use the `CategoricalCrossentropy` as the loss function. And, for the
optimizer, I use `Adamax`.)
"""

model.compile(
    loss=tf.keras.losses.CategoricalCrossentropy(),
    optimizer=tf.keras.optimizers.Adamax(),
    metrics=['accuracy']
)

"""Implementing **tensorboard callback** to track and visualizate the metrics (accuracy)."""

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

"""Fitting the model to the dataset with
<br>`steps per epoch = ceil(number of training data/training batch size) = ceil(1314/32) = 42`
<br>`validation steps = ceil(number of validation data/validation batch size) = ceil(874/32) = 28`
"""

history = model.fit(
              train_generator,
              steps_per_epoch=42,
              epochs=20,
              validation_data=val_generator,
              validation_steps=28,
              verbose=2,
              callbacks=[tensorboard_callback]
           )
history

!tensorboard --logdir logs

history.history.keys()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.ylim(0, 1)
plt.tight_layout()
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.ylim(0, 1)
plt.tight_layout()
plt.show()

"""Testing the model."""

from google.colab import files
from tensorflow.keras.preprocessing import image
import numpy as np

uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size=(200, 300))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  output_class = np.argmax(classes)
  print(fn)
  if output_class == 0:
    print('Paper')
  elif output_class == 1:
    print('Rock')
  else:
    print('Scissors')

"""Thank you."""